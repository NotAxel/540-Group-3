{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a8ac0d-500b-450c-ae8d-e9444fe6de23",
   "metadata": {},
   "source": [
    "# Machine Learning for E-Commerce User Predictions \n",
    "## AWS Platform\n",
    "### Axel (Titouan) Magret, Gurleen Virk,  Victor Hsu\n",
    "\n",
    "### AAI 540 Group 3\n",
    "### October 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10e8e96c-edc8-432d-b8a9-3ba42d1d427f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T03:54:15.596209Z",
     "iopub.status.busy": "2025-10-01T03:54:15.595913Z",
     "iopub.status.idle": "2025-10-01T03:54:21.067264Z",
     "shell.execute_reply": "2025-10-01T03:54:21.066550Z",
     "shell.execute_reply.started": "2025-10-01T03:54:15.596149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import io\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da779bad-ea17-4b97-b307-adde2f66dec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T03:55:43.828803Z",
     "iopub.status.busy": "2025-10-01T03:55:43.828523Z",
     "iopub.status.idle": "2025-10-01T03:55:44.175669Z",
     "shell.execute_reply": "2025-10-01T03:55:44.174689Z",
     "shell.execute_reply.started": "2025-10-01T03:55:43.828780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Role ARN: arn:aws:iam::654654600015:role/LabRole\n",
      "Default S3 Bucket: sagemaker-us-east-1-654654600015\n",
      "Our Project Bucket: aai540-ecommerce-recommendation-project-group3\n"
     ]
    }
   ],
   "source": [
    "# Set S3 configurations\n",
    "BUCKET_NAME = 'aai540-ecommerce-recommendation-project-group3'  # team bucket\n",
    "S3_PREFIX = '' \n",
    "PROCESSED_PREFIX = 'processed/'\n",
    "\n",
    "# Dataset file names\n",
    "RAW_FILES = [\n",
    "    'oct_2019_sample.csv',\n",
    "    'nov_2019_sample.csv', \n",
    "    'jan_2020_sample.csv',\n",
    "    'train_user_product_pairs.csv',\n",
    "    'validation_user_product_pairs.csv'\n",
    "]\n",
    "\n",
    "# Initialize AWS services\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "s3_client = boto3.client('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "print(f\"SageMaker Role ARN: {role}\")\n",
    "print(f\"Default S3 Bucket: {sagemaker_session.default_bucket()}\")\n",
    "print(f\"Our Project Bucket: {BUCKET_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e83626-6c4d-4249-a8cb-8a06d5e12eb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T03:56:47.944188Z",
     "iopub.status.busy": "2025-10-01T03:56:47.943892Z",
     "iopub.status.idle": "2025-10-01T03:56:47.950964Z",
     "shell.execute_reply": "2025-10-01T03:56:47.950173Z",
     "shell.execute_reply.started": "2025-10-01T03:56:47.944164Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify S3 files all exist\n",
    "def verify_s3_files(bucket_name=BUCKET_NAME, s3_prefix=S3_PREFIX):\n",
    "    print(\"VERIFYING S3 FILES\")\n",
    "    print(f\"\\nBucket: {bucket_name}\")\n",
    "    print(f\"Prefix: {s3_prefix if s3_prefix else '(root)'}\")\n",
    "    \n",
    "    print(\"\\nChecking for required files...\")\n",
    "    \n",
    "    all_files_exist = True\n",
    "    for filename in RAW_FILES:\n",
    "        s3_key = f\"{s3_prefix}{filename}\" if s3_prefix else filename\n",
    "        \n",
    "        try:\n",
    "            s3_client.head_object(Bucket=bucket_name, Key=s3_key)\n",
    "            print(f\"  ✓ {filename}\")\n",
    "            \n",
    "            # Get file size\n",
    "            response = s3_client.head_object(Bucket=bucket_name, Key=s3_key)\n",
    "            size_mb = response['ContentLength'] / (1024 * 1024)\n",
    "            print(f\"    Location: s3://{bucket_name}/{s3_key}\")\n",
    "            print(f\"    Size: {size_mb:.2f} MB\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ {filename} - NOT FOUND\")\n",
    "            print(f\"    Expected location: s3://{bucket_name}/{s3_key}\")\n",
    "            all_files_exist = False\n",
    "    \n",
    "    if all_files_exist:\n",
    "        print(\"\\n✓ All files found in S3!\")\n",
    "    else:\n",
    "        print(\"\\n✗ Some files are missing. Please check:\")\n",
    "        print(f\"   1. Bucket name: {bucket_name}\")\n",
    "        print(f\"   2. File names match exactly (case-sensitive)\")\n",
    "        print(f\"   3. Files are in correct location\")\n",
    "        \n",
    "        # List what's in the bucket\n",
    "        print(\"\\nFiles currently in bucket:\")\n",
    "        try:\n",
    "            response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=s3_prefix)\n",
    "            if 'Contents' in response:\n",
    "                for obj in response['Contents']:\n",
    "                    print(f\"  - {obj['Key']}\")\n",
    "            else:\n",
    "                print(\"  (bucket is empty)\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error listing bucket: {str(e)}\")\n",
    "    \n",
    "    return all_files_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8374094-2540-4240-93e3-c97d780d4071",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T03:57:43.925089Z",
     "iopub.status.busy": "2025-10-01T03:57:43.924809Z",
     "iopub.status.idle": "2025-10-01T03:57:43.935556Z",
     "shell.execute_reply": "2025-10-01T03:57:43.934584Z",
     "shell.execute_reply.started": "2025-10-01T03:57:43.925066Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data from S3 bucket\n",
    "def load_data_from_s3(bucket_name=BUCKET_NAME, s3_prefix=S3_PREFIX):\n",
    "    print(\"=\"*90)\n",
    "    print(\"LOADING DATA FROM S3\")\n",
    "    \n",
    "    # Load training data\n",
    "    train_filename = 'train_user_product_pairs.csv'\n",
    "    train_key = f\"{s3_prefix}{train_filename}\" if s3_prefix else train_filename\n",
    "    print(f\"\\nLoading training data from s3://{bucket_name}/{train_key}\")\n",
    "    \n",
    "    try:\n",
    "        obj = s3_client.get_object(Bucket=bucket_name, Key=train_key)\n",
    "        df_train = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "        print(f\"✓ Training data loaded: {df_train.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading training data: {str(e)}\")\n",
    "        print(\"\\nTroubleshooting:\")\n",
    "        print(\"1. Check if bucket name is correct\")\n",
    "        print(\"2. Verify files were uploaded to S3\")\n",
    "        print(\"3. Check S3 permissions\")\n",
    "        print(\"4. Verify file name matches exactly (case-sensitive)\")\n",
    "        return None, None\n",
    "    \n",
    "    # Load validation data\n",
    "    val_filename = 'validation_user_product_pairs.csv'\n",
    "    val_key = f\"{s3_prefix}{val_filename}\" if s3_prefix else val_filename\n",
    "    print(f\"\\nLoading validation data from s3://{bucket_name}/{val_key}\")\n",
    "    \n",
    "    try:\n",
    "        obj = s3_client.get_object(Bucket=bucket_name, Key=val_key)\n",
    "        df_val = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "        print(f\"✓ Validation data loaded: {df_val.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading validation data: {str(e)}\")\n",
    "        return df_train, None\n",
    "    \n",
    "    # Display basic info\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"DATASET SUMMARY\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    print(f\"\\nTraining data:\")\n",
    "    print(f\"  Shape: {df_train.shape}\")\n",
    "    print(f\"  Columns: {df_train.columns.tolist()}\")\n",
    "    print(f\"  Purchase rate: {df_train['purchased'].mean()*100:.2f}%\")\n",
    "    print(f\"  Missing values: {df_train.isnull().sum().sum()}\")\n",
    "    \n",
    "    print(f\"\\nValidation data:\")\n",
    "    print(f\"  Shape: {df_val.shape}\")\n",
    "    print(f\"  Purchase rate: {df_val['purchased'].mean()*100:.2f}%\")\n",
    "    print(f\"  Missing values: {df_val.isnull().sum().sum()}\")\n",
    "    \n",
    "    print(f\"\\nFirst few rows of training data:\")\n",
    "    print(df_train.head())\n",
    "    \n",
    "    return df_train, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e28d8ea6-c54e-43bb-8cea-c3d959b1f50a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T03:58:23.219930Z",
     "iopub.status.busy": "2025-10-01T03:58:23.219652Z",
     "iopub.status.idle": "2025-10-01T03:58:23.227247Z",
     "shell.execute_reply": "2025-10-01T03:58:23.226530Z",
     "shell.execute_reply.started": "2025-10-01T03:58:23.219909Z"
    }
   },
   "outputs": [],
   "source": [
    "# Handle missing values in categorical and numeric columns\n",
    "def handle_missing_values(df_train, df_val):\n",
    "    print(\"HANDLING MISSING VALUES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Make copies\n",
    "    df_train = df_train.copy()\n",
    "    df_val = df_val.copy()\n",
    "    \n",
    "    print(\"\\nMissing values BEFORE handling:\")\n",
    "    print(\"\\nTraining set:\")\n",
    "    missing_train = df_train.isnull().sum()\n",
    "    print(missing_train[missing_train > 0])\n",
    "    \n",
    "    print(\"\\nValidation set:\")\n",
    "    missing_val = df_val.isnull().sum()\n",
    "    print(missing_val[missing_val > 0])\n",
    "    \n",
    "    # Handle categorical columns\n",
    "    categorical_cols = ['category_code', 'brand']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in df_train.columns:\n",
    "            train_missing = df_train[col].isnull().sum()\n",
    "            val_missing = df_val[col].isnull().sum()\n",
    "            \n",
    "            # Fill with 'unknown'\n",
    "            df_train[col] = df_train[col].fillna('unknown')\n",
    "            df_val[col] = df_val[col].fillna('unknown')\n",
    "            \n",
    "            print(f\"\\n✓ {col}:\")\n",
    "            print(f\"    Training: Filled {train_missing:,} ({train_missing/len(df_train)*100:.1f}%)\")\n",
    "            print(f\"    Validation: Filled {val_missing:,} ({val_missing/len(df_val)*100:.1f}%)\")\n",
    "    \n",
    "    # Handle numeric columns (if any remaining nulls)\n",
    "    numeric_cols = df_train.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if df_train[col].isnull().sum() > 0:\n",
    "            median_val = df_train[col].median()\n",
    "            df_train[col] = df_train[col].fillna(median_val)\n",
    "            df_val[col] = df_val[col].fillna(median_val)\n",
    "            print(f\"\\n✓ {col}: Filled with median ({median_val:.2f})\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Missing values AFTER handling:\")\n",
    "    print(f\"  Training: {df_train.isnull().sum().sum()} total\")\n",
    "    print(f\"  Validation: {df_val.isnull().sum().sum()} total\")\n",
    "    print(\"✓ All missing values handled!\")\n",
    "    \n",
    "    return df_train, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bef23c74-8860-4bcd-8474-2ff81bb7f985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T03:58:59.609699Z",
     "iopub.status.busy": "2025-10-01T03:58:59.609430Z",
     "iopub.status.idle": "2025-10-01T03:58:59.615704Z",
     "shell.execute_reply": "2025-10-01T03:58:59.614813Z",
     "shell.execute_reply.started": "2025-10-01T03:58:59.609677Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encode categorical features using Label Encoding\n",
    "def encode_categorical_features(df_train, df_val):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ENCODING CATEGORICAL FEATURES\")\n",
    "    print(\"Method: Label Encoding\")\n",
    "    \n",
    "    df_train = df_train.copy()\n",
    "    df_val = df_val.copy()\n",
    "    \n",
    "    categorical_cols = ['category_code', 'brand']\n",
    "    label_encoders = {}\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in df_train.columns:\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"  Unique categories in training: {df_train[col].nunique():,}\")\n",
    "            print(f\"  Top 5 categories: {df_train[col].value_counts().head().to_dict()}\")\n",
    "            \n",
    "            # Initialize and fit encoder\n",
    "            le = LabelEncoder()\n",
    "            le.fit(df_train[col])\n",
    "            \n",
    "            # Transform training data\n",
    "            df_train[col + '_encoded'] = le.transform(df_train[col])\n",
    "            \n",
    "            # Transform validation data (handle unseen categories)\n",
    "            df_val[col + '_encoded'] = df_val[col].apply(\n",
    "                lambda x: le.transform([x])[0] if x in le.classes_ else -1\n",
    "            )\n",
    "            \n",
    "            unseen_count = (df_val[col + '_encoded'] == -1).sum()\n",
    "            print(f\"  Encoded range: 0 to {df_train[col + '_encoded'].max()}\")\n",
    "            print(f\"  Unseen categories in validation: {unseen_count} ({unseen_count/len(df_val)*100:.1f}%)\")\n",
    "            \n",
    "            # Store encoder\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    print(\"\\n✓ Categorical encoding complete!\")\n",
    "    \n",
    "    return df_train, df_val, label_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b12a54e0-68a8-4896-b4cd-be4dc8696109",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T03:59:53.008483Z",
     "iopub.status.busy": "2025-10-01T03:59:53.008041Z",
     "iopub.status.idle": "2025-10-01T03:59:53.021441Z",
     "shell.execute_reply": "2025-10-01T03:59:53.020689Z",
     "shell.execute_reply.started": "2025-10-01T03:59:53.008456Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select and prepare final features for model training\n",
    "def prepare_modeling_features(df_train, df_val):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PREPARING FEATURES FOR MODELING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Define feature columns\n",
    "    feature_cols = [\n",
    "        # User-product interaction features\n",
    "        'view_count',\n",
    "        'cart_count',\n",
    "        'total_interactions',\n",
    "        \n",
    "        # Product features\n",
    "        'price',\n",
    "        'category_id',\n",
    "        'category_code_encoded',\n",
    "        'brand_encoded',\n",
    "        'product_view_count',\n",
    "        'product_purchase_count',\n",
    "        'product_conversion_rate',\n",
    "        \n",
    "        # User behavior features\n",
    "        'user_total_events',\n",
    "        'user_total_purchases'\n",
    "    ]\n",
    "    \n",
    "    # Verify all features exist\n",
    "    missing_features = [col for col in feature_cols if col not in df_train.columns]\n",
    "    if missing_features:\n",
    "        print(f\"⚠ Warning: Missing features: {missing_features}\")\n",
    "        feature_cols = [col for col in feature_cols if col in df_train.columns]\n",
    "    \n",
    "    print(f\"\\nSelected {len(feature_cols)} features:\")\n",
    "    for i, col in enumerate(feature_cols, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "    \n",
    "    # Extract features and target\n",
    "    X_train = df_train[feature_cols].copy()\n",
    "    y_train = df_train['purchased'].copy()\n",
    "    \n",
    "    X_val = df_val[feature_cols].copy()\n",
    "    y_val = df_val['purchased'].copy()\n",
    "    \n",
    "    # Final data quality checks\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"DATA QUALITY CHECKS\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    print(f\"\\nShapes:\")\n",
    "    print(f\"  X_train: {X_train.shape}\")\n",
    "    print(f\"  y_train: {y_train.shape}\")\n",
    "    print(f\"  X_val: {X_val.shape}\")\n",
    "    print(f\"  y_val: {y_val.shape}\")\n",
    "    \n",
    "    print(f\"\\nClass Distribution:\")\n",
    "    print(f\"  Training:\")\n",
    "    print(f\"    Purchased (1): {y_train.sum():,} ({y_train.mean()*100:.2f}%)\")\n",
    "    print(f\"    Not Purchased (0): {(~y_train.astype(bool)).sum():,} ({(1-y_train.mean())*100:.2f}%)\")\n",
    "    print(f\"  Validation:\")\n",
    "    print(f\"    Purchased (1): {y_val.sum():,} ({y_val.mean()*100:.2f}%)\")\n",
    "    print(f\"    Not Purchased (0): {(~y_val.astype(bool)).sum():,} ({(1-y_val.mean())*100:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nData Quality:\")\n",
    "    print(f\"  Missing values in X_train: {X_train.isnull().sum().sum()}\")\n",
    "    print(f\"  Missing values in X_val: {X_val.isnull().sum().sum()}\")\n",
    "    print(f\"  Infinite values in X_train: {np.isinf(X_train.values).sum()}\")\n",
    "    print(f\"  Infinite values in X_val: {np.isinf(X_val.values).sum()}\")\n",
    "    \n",
    "    if X_train.isnull().sum().sum() == 0 and np.isinf(X_train.values).sum() == 0:\n",
    "        print(\"\\n✓ Data quality checks passed!\")\n",
    "    else:\n",
    "        print(\"\\n⚠ Warning: Data quality issues detected!\")\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fd74f81-9022-479d-844c-933848e460a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T04:00:54.564856Z",
     "iopub.status.busy": "2025-10-01T04:00:54.564579Z",
     "iopub.status.idle": "2025-10-01T04:00:54.570943Z",
     "shell.execute_reply": "2025-10-01T04:00:54.570058Z",
     "shell.execute_reply.started": "2025-10-01T04:00:54.564836Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save processed data to S3 bucket for team access and model training\n",
    "def save_processed_data_to_s3(X_train, y_train, X_val, y_val, \n",
    "                               bucket_name=BUCKET_NAME, \n",
    "                               s3_prefix=PROCESSED_PREFIX):\n",
    "    print(\"SAVING PROCESSED DATA TO S3\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Combine features and target\n",
    "    train_processed = X_train.copy()\n",
    "    train_processed['purchased'] = y_train.values\n",
    "    \n",
    "    val_processed = X_val.copy()\n",
    "    val_processed['purchased'] = y_val.values\n",
    "    \n",
    "    # Save to S3\n",
    "    datasets = {\n",
    "        'train_processed.csv': train_processed,\n",
    "        'validation_processed.csv': val_processed\n",
    "    }\n",
    "    \n",
    "    for filename, df in datasets.items():\n",
    "        s3_key = f\"{s3_prefix}{filename}\" if s3_prefix else filename\n",
    "        \n",
    "        print(f\"\\nSaving {filename}...\")\n",
    "        print(f\"  Shape: {df.shape}\")\n",
    "        print(f\"  S3 location: s3://{bucket_name}/{s3_key}\")\n",
    "        \n",
    "        try:\n",
    "            # Convert to CSV in memory\n",
    "            csv_buffer = io.StringIO()\n",
    "            df.to_csv(csv_buffer, index=False)\n",
    "            \n",
    "            # Upload to S3\n",
    "            s3_client.put_object(\n",
    "                Bucket=bucket_name,\n",
    "                Key=s3_key,\n",
    "                Body=csv_buffer.getvalue()\n",
    "            )\n",
    "            \n",
    "            print(f\"  ✓ Saved!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error: {str(e)}\")\n",
    "    \n",
    "    print(\"\\n✓ All processed data saved to S3!\")\n",
    "    print(f\"\\nYour team can now access processed data from:\")\n",
    "    print(f\"  s3://{bucket_name}/{s3_prefix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fdf3751-b282-42f0-b776-7ab52fc20011",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T04:01:58.125036Z",
     "iopub.status.busy": "2025-10-01T04:01:58.124770Z",
     "iopub.status.idle": "2025-10-01T04:01:58.132313Z",
     "shell.execute_reply": "2025-10-01T04:01:58.131746Z",
     "shell.execute_reply.started": "2025-10-01T04:01:58.125014Z"
    }
   },
   "outputs": [],
   "source": [
    "# Complete data processing pipeline\n",
    "def run_complete_pipeline():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPLETE DATA PREPROCESSING PIPELINE\")\n",
    "    print(f\"\\nBucket: {BUCKET_NAME}\")\n",
    "    print(f\"Region: {sagemaker_session.boto_region_name}\")\n",
    "    \n",
    "    # Step 0: Verify S3 files exist\n",
    "    print(\"\\n>>> STEP 0: Verifying S3 files\")\n",
    "    files_exist = verify_s3_files(BUCKET_NAME, S3_PREFIX)\n",
    "    \n",
    "    if not files_exist:\n",
    "        print(\"\\n✗ Cannot proceed - required files not found in S3\")\n",
    "        print(\"\\nPlease ensure all files are uploaded to:\")\n",
    "        print(f\"  s3://{BUCKET_NAME}/{S3_PREFIX if S3_PREFIX else '(root)'}\")\n",
    "        return None\n",
    "    \n",
    "    # Step 1: Load data from S3\n",
    "    print(\"\\n>>> STEP 1: Loading data from S3\")\n",
    "    df_train, df_val = load_data_from_s3(BUCKET_NAME, S3_PREFIX)\n",
    "    \n",
    "    if df_train is None or df_val is None:\n",
    "        print(\"\\n✗ Failed to load data. Please check S3 setup.\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Handle missing values\n",
    "    print(\"\\n>>> STEP 2: Handling missing values\")\n",
    "    df_train, df_val = handle_missing_values(df_train, df_val)\n",
    "    \n",
    "    # Step 3: Encode categorical features\n",
    "    print(\"\\n>>> STEP 3: Encoding categorical features\")\n",
    "    df_train, df_val, encoders = encode_categorical_features(df_train, df_val)\n",
    "    \n",
    "    # Step 4: Prepare features\n",
    "    print(\"\\n>>> STEP 4: Preparing features for modeling\")\n",
    "    X_train, y_train, X_val, y_val, features = prepare_modeling_features(df_train, df_val)\n",
    "    \n",
    "    # Step 5: Save processed data\n",
    "    print(\"\\n>>> STEP 5: Saving processed data to S3\")\n",
    "    save_processed_data_to_s3(X_train, y_train, X_val, y_val, BUCKET_NAME, PROCESSED_PREFIX)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PIPELINE COMPLETE! ✓\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n Data Ready for Model Training:\")\n",
    "    print(f\"  Training samples: {len(X_train):,}\")\n",
    "    print(f\"  Validation samples: {len(X_val):,}\")\n",
    "    print(f\"  Features: {len(features)}\")\n",
    "    print(f\"  Target: 'purchased' (binary: 0/1)\")\n",
    "    \n",
    "    print(\"\\n Processed data saved to:\")\n",
    "    print(f\"  s3://{BUCKET_NAME}/{PROCESSED_PREFIX}train_processed.csv\")\n",
    "    print(f\"  s3://{BUCKET_NAME}/{PROCESSED_PREFIX}validation_processed.csv\")\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, features, encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a3be07-5bcf-498a-9581-66ace7fac58f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T04:02:23.996306Z",
     "iopub.status.busy": "2025-10-01T04:02:23.995993Z",
     "iopub.status.idle": "2025-10-01T04:52:34.680858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPLETE DATA PREPROCESSING PIPELINE\n",
      "\n",
      "Bucket: aai540-ecommerce-recommendation-project-group3\n",
      "Region: us-east-1\n",
      "\n",
      ">>> STEP 0: Verifying S3 files\n",
      "VERIFYING S3 FILES\n",
      "\n",
      "Bucket: aai540-ecommerce-recommendation-project-group3\n",
      "Prefix: (root)\n",
      "\n",
      "Checking for required files...\n",
      "  ✓ oct_2019_sample.csv\n",
      "    Location: s3://aai540-ecommerce-recommendation-project-group3/oct_2019_sample.csv\n",
      "    Size: 151.36 MB\n",
      "  ✓ nov_2019_sample.csv\n",
      "    Location: s3://aai540-ecommerce-recommendation-project-group3/nov_2019_sample.csv\n",
      "    Size: 262.94 MB\n",
      "  ✓ jan_2020_sample.csv\n",
      "    Location: s3://aai540-ecommerce-recommendation-project-group3/jan_2020_sample.csv\n",
      "    Size: 241.01 MB\n",
      "  ✓ train_user_product_pairs.csv\n",
      "    Location: s3://aai540-ecommerce-recommendation-project-group3/train_user_product_pairs.csv\n",
      "    Size: 297.99 MB\n",
      "  ✓ validation_user_product_pairs.csv\n",
      "    Location: s3://aai540-ecommerce-recommendation-project-group3/validation_user_product_pairs.csv\n",
      "    Size: 160.76 MB\n",
      "\n",
      "✓ All files found in S3!\n",
      "\n",
      ">>> STEP 1: Loading data from S3\n",
      "==========================================================================================\n",
      "LOADING DATA FROM S3\n",
      "\n",
      "Loading training data from s3://aai540-ecommerce-recommendation-project-group3/train_user_product_pairs.csv\n",
      "✓ Training data loaded: (2018753, 17)\n",
      "\n",
      "Loading validation data from s3://aai540-ecommerce-recommendation-project-group3/validation_user_product_pairs.csv\n",
      "✓ Validation data loaded: (1062101, 17)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATASET SUMMARY\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training data:\n",
      "  Shape: (2018753, 17)\n",
      "  Columns: ['user_id', 'product_id', 'purchased', 'view_count', 'cart_count', 'total_interactions', 'price', 'category_id', 'category_code', 'brand', 'first_interaction', 'last_interaction', 'product_view_count', 'product_purchase_count', 'product_conversion_rate', 'user_total_events', 'user_total_purchases']\n",
      "  Purchase rate: 62.26%\n",
      "  Missing values: 758188\n",
      "\n",
      "Validation data:\n",
      "  Shape: (1062101, 17)\n",
      "  Purchase rate: 58.43%\n",
      "  Missing values: 173875\n",
      "\n",
      "First few rows of training data:\n",
      "     user_id  product_id  purchased  view_count  cart_count  \\\n",
      "0  107837897     4700557          0           0           1   \n",
      "1  122966408    32801147          0           1           0   \n",
      "2  125917727    30100067          0           0           1   \n",
      "3  138340325    17301041          1           0           0   \n",
      "4  154128341    11700129          0           0           1   \n",
      "\n",
      "   total_interactions   price          category_id  \\\n",
      "0                   1  137.20  2053013560899928785   \n",
      "1                   1  399.42  2055156924273394455   \n",
      "2                   1   85.75  2053013556110033341   \n",
      "3                   1   93.50  2053013553853497655   \n",
      "4                   1  236.81  2053013554591695207   \n",
      "\n",
      "                    category_code     brand        first_interaction  \\\n",
      "0  auto.accessories.videoregister    sho-me  2019-11-29 05:00:04 UTC   \n",
      "1                             NaN       NaN  2019-11-23 09:36:13 UTC   \n",
      "2                             NaN    dewalt  2019-11-08 17:14:26 UTC   \n",
      "3                             NaN  shiseido  2019-11-11 05:47:14 UTC   \n",
      "4      electronics.audio.acoustic    yamaha  2019-11-13 16:59:29 UTC   \n",
      "\n",
      "          last_interaction  product_view_count  product_purchase_count  \\\n",
      "0  2019-11-29 05:00:04 UTC                  87                      40   \n",
      "1  2019-11-23 09:36:13 UTC                   8                       6   \n",
      "2  2019-11-08 17:14:26 UTC                  99                      56   \n",
      "3  2019-11-11 05:47:14 UTC                  35                      12   \n",
      "4  2019-11-13 16:59:29 UTC                  11                       5   \n",
      "\n",
      "   product_conversion_rate  user_total_events  user_total_purchases  \n",
      "0                 0.459770                  1                     0  \n",
      "1                 0.750000                  1                     0  \n",
      "2                 0.565657                  1                     0  \n",
      "3                 0.342857                  1                     1  \n",
      "4                 0.454545                  1                     0  \n",
      "\n",
      ">>> STEP 2: Handling missing values\n",
      "HANDLING MISSING VALUES\n",
      "================================================================================\n",
      "\n",
      "Missing values BEFORE handling:\n",
      "\n",
      "Training set:\n",
      "category_code    564135\n",
      "brand            194053\n",
      "dtype: int64\n",
      "\n",
      "Validation set:\n",
      "category_code    83650\n",
      "brand            90225\n",
      "dtype: int64\n",
      "\n",
      "✓ category_code:\n",
      "    Training: Filled 564,135 (27.9%)\n",
      "    Validation: Filled 83,650 (7.9%)\n",
      "\n",
      "✓ brand:\n",
      "    Training: Filled 194,053 (9.6%)\n",
      "    Validation: Filled 90,225 (8.5%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Missing values AFTER handling:\n",
      "  Training: 0 total\n",
      "  Validation: 0 total\n",
      "✓ All missing values handled!\n",
      "\n",
      ">>> STEP 3: Encoding categorical features\n",
      "\n",
      "================================================================================\n",
      "ENCODING CATEGORICAL FEATURES\n",
      "Method: Label Encoding\n",
      "\n",
      "category_code:\n",
      "  Unique categories in training: 130\n",
      "  Top 5 categories: {'electronics.smartphone': 734069, 'unknown': 564135, 'electronics.audio.headphone': 74400, 'electronics.video.tv': 67727, 'electronics.clocks': 50934}\n",
      "  Encoded range: 0 to 129\n",
      "  Unseen categories in validation: 1336 (0.1%)\n",
      "\n",
      "brand:\n",
      "  Unique categories in training: 3,250\n",
      "  Top 5 categories: {'samsung': 383128, 'apple': 296645, 'unknown': 194053, 'xiaomi': 153670, 'huawei': 53689}\n",
      "  Encoded range: 0 to 3249\n",
      "  Unseen categories in validation: 13927 (1.3%)\n",
      "\n",
      "✓ Categorical encoding complete!\n",
      "\n",
      ">>> STEP 4: Preparing features for modeling\n",
      "\n",
      "================================================================================\n",
      "PREPARING FEATURES FOR MODELING\n",
      "================================================================================\n",
      "\n",
      "Selected 12 features:\n",
      "   1. view_count\n",
      "   2. cart_count\n",
      "   3. total_interactions\n",
      "   4. price\n",
      "   5. category_id\n",
      "   6. category_code_encoded\n",
      "   7. brand_encoded\n",
      "   8. product_view_count\n",
      "   9. product_purchase_count\n",
      "  10. product_conversion_rate\n",
      "  11. user_total_events\n",
      "  12. user_total_purchases\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATA QUALITY CHECKS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Shapes:\n",
      "  X_train: (2018753, 12)\n",
      "  y_train: (2018753,)\n",
      "  X_val: (1062101, 12)\n",
      "  y_val: (1062101,)\n",
      "\n",
      "Class Distribution:\n",
      "  Training:\n",
      "    Purchased (1): 1,256,878 (62.26%)\n",
      "    Not Purchased (0): 761,875 (37.74%)\n",
      "  Validation:\n",
      "    Purchased (1): 620,577 (58.43%)\n",
      "    Not Purchased (0): 441,524 (41.57%)\n",
      "\n",
      "Data Quality:\n",
      "  Missing values in X_train: 0\n",
      "  Missing values in X_val: 0\n",
      "  Infinite values in X_train: 0\n",
      "  Infinite values in X_val: 0\n",
      "\n",
      "✓ Data quality checks passed!\n",
      "\n",
      ">>> STEP 5: Saving processed data to S3\n",
      "SAVING PROCESSED DATA TO S3\n",
      "================================================================================\n",
      "\n",
      "Saving train_processed.csv...\n",
      "  Shape: (2018753, 13)\n",
      "  S3 location: s3://aai540-ecommerce-recommendation-project-group3/processed/train_processed.csv\n",
      "  ✓ Saved!\n",
      "\n",
      "Saving validation_processed.csv...\n",
      "  Shape: (1062101, 13)\n",
      "  S3 location: s3://aai540-ecommerce-recommendation-project-group3/processed/validation_processed.csv\n",
      "  ✓ Saved!\n",
      "\n",
      "✓ All processed data saved to S3!\n",
      "\n",
      "Your team can now access processed data from:\n",
      "  s3://aai540-ecommerce-recommendation-project-group3/processed/\n",
      "\n",
      "================================================================================\n",
      "PIPELINE COMPLETE! ✓\n",
      "================================================================================\n",
      "\n",
      "📊 Data Ready for Model Training:\n",
      "  Training samples: 2,018,753\n",
      "  Validation samples: 1,062,101\n",
      "  Features: 12\n",
      "  Target: 'purchased' (binary: 0/1)\n",
      "\n",
      "📁 Processed data saved to:\n",
      "  s3://aai540-ecommerce-recommendation-project-group3/processed/train_processed.csv\n",
      "  s3://aai540-ecommerce-recommendation-project-group3/processed/validation_processed.csv\n",
      "\n",
      "================================================================================\n",
      "FINAL PREPROCESSED DATA\n",
      "================================================================================\n",
      "\n",
      "X_train shape: (2018753, 12)\n",
      "y_train shape: (2018753,)\n",
      "\n",
      "Features: ['view_count', 'cart_count', 'total_interactions', 'price', 'category_id', 'category_code_encoded', 'brand_encoded', 'product_view_count', 'product_purchase_count', 'product_conversion_rate', 'user_total_events', 'user_total_purchases']\n",
      "\n",
      "Sample of training data:\n",
      "   view_count  cart_count  total_interactions   price          category_id  \\\n",
      "0           0           1                   1  137.20  2053013560899928785   \n",
      "1           1           0                   1  399.42  2055156924273394455   \n",
      "2           0           1                   1   85.75  2053013556110033341   \n",
      "3           0           0                   1   93.50  2053013553853497655   \n",
      "4           0           1                   1  236.81  2053013554591695207   \n",
      "\n",
      "   category_code_encoded  brand_encoded  product_view_count  \\\n",
      "0                     61           2617                  87   \n",
      "1                    129           2995                   8   \n",
      "2                    129            744                  99   \n",
      "3                    129           2615                  35   \n",
      "4                     92           3186                  11   \n",
      "\n",
      "   product_purchase_count  product_conversion_rate  user_total_events  \\\n",
      "0                      40                 0.459770                  1   \n",
      "1                       6                 0.750000                  1   \n",
      "2                      56                 0.565657                  1   \n",
      "3                      12                 0.342857                  1   \n",
      "4                       5                 0.454545                  1   \n",
      "\n",
      "   user_total_purchases  \n",
      "0                     0  \n",
      "1                     0  \n",
      "2                     0  \n",
      "3                     1  \n",
      "4                     0  \n",
      "\n",
      "Target distribution:\n",
      "purchased\n",
      "1    1256878\n",
      "0     761875\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Execute\n",
    "X_train, y_train, X_val, y_val, features, encoders = run_complete_pipeline()\n",
    "\n",
    "# Display final data\n",
    "if X_train is not None:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FINAL PREPROCESSED DATA\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nX_train shape: {X_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    print(f\"\\nFeatures: {features}\")\n",
    "    print(f\"\\nSample of training data:\")\n",
    "    print(X_train.head())\n",
    "    print(f\"\\nTarget distribution:\")\n",
    "    print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722527c6-e80f-492c-a1d8-ce0acf83776e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
